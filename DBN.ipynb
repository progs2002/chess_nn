{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(773,100)\n",
    "        self.fc2 = nn.Linear(100,100)\n",
    "        self.fc3 = nn.Linear(100,100)\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbn = DBN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from extractor import get_dataset\n",
    "path = 'dataset/games.pgn'\n",
    "num_games = 50\n",
    "\n",
    "X, Y = get_dataset(path, num_games)\n",
    "X = X.type(torch.FloatTensor)\n",
    "Y = Y.type(torch.FloatTensor)\n",
    "len_data = X.shape[0]\n",
    "split = int(len_data*0.8)\n",
    "X_train = X[:split,:]\n",
    "X_test = X[split:,:]\n",
    "Y_train = Y[:split]\n",
    "Y_test = Y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbn_dataset = TensorDataset(X, torch.zeros((X.shape[0])))\n",
    "dbn_dataloader = DataLoader(dbn_dataset, batch_size=64, shuffle=True)\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "train_datalaoder = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test, Y_test)\n",
    "test_datalaoder = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "[1,     6] loss: 26.407\n",
      "[1,    12] loss: 8.206\n",
      "[1,    18] loss: 6.154\n",
      "[1,    24] loss: 5.337\n",
      "[1,    30] loss: 5.045\n",
      "[1,    36] loss: 4.740\n",
      "[1,    42] loss: 4.526\n",
      "[1,    48] loss: 4.358\n",
      "[1,    54] loss: 4.418\n",
      "[1,    60] loss: 4.317\n",
      "[1,    66] loss: 4.345\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[2,     6] loss: 4.214\n",
      "[2,    12] loss: 4.109\n",
      "[2,    18] loss: 3.979\n",
      "[2,    24] loss: 4.141\n",
      "[2,    30] loss: 4.196\n",
      "[2,    36] loss: 4.034\n",
      "[2,    42] loss: 4.018\n",
      "[2,    48] loss: 4.087\n",
      "[2,    54] loss: 3.964\n",
      "[2,    60] loss: 4.030\n",
      "[2,    66] loss: 4.055\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[3,     6] loss: 4.081\n",
      "[3,    12] loss: 4.074\n",
      "[3,    18] loss: 4.021\n",
      "[3,    24] loss: 3.924\n",
      "[3,    30] loss: 3.899\n",
      "[3,    36] loss: 3.780\n",
      "[3,    42] loss: 3.927\n",
      "[3,    48] loss: 3.939\n",
      "[3,    54] loss: 3.937\n",
      "[3,    60] loss: 3.872\n",
      "[3,    66] loss: 3.982\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4,     6] loss: 4.047\n",
      "[4,    12] loss: 3.788\n",
      "[4,    18] loss: 3.927\n",
      "[4,    24] loss: 3.852\n",
      "[4,    30] loss: 3.903\n",
      "[4,    36] loss: 3.882\n",
      "[4,    42] loss: 4.033\n",
      "[4,    48] loss: 3.817\n",
      "[4,    54] loss: 3.872\n",
      "[4,    60] loss: 3.795\n",
      "[4,    66] loss: 3.957\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[5,     6] loss: 3.780\n",
      "[5,    12] loss: 3.943\n",
      "[5,    18] loss: 3.815\n",
      "[5,    24] loss: 3.821\n",
      "[5,    30] loss: 3.869\n",
      "[5,    36] loss: 3.939\n",
      "[5,    42] loss: 3.759\n",
      "[5,    48] loss: 3.885\n",
      "[5,    54] loss: 3.899\n",
      "[5,    60] loss: 3.961\n",
      "[5,    66] loss: 3.915\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[6,     6] loss: 3.869\n",
      "[6,    12] loss: 3.835\n",
      "[6,    18] loss: 3.759\n",
      "[6,    24] loss: 3.851\n",
      "[6,    30] loss: 3.900\n",
      "[6,    36] loss: 3.821\n",
      "[6,    42] loss: 3.911\n",
      "[6,    48] loss: 3.821\n",
      "[6,    54] loss: 3.927\n",
      "[6,    60] loss: 3.793\n",
      "[6,    66] loss: 3.902\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[7,     6] loss: 3.919\n",
      "[7,    12] loss: 3.859\n",
      "[7,    18] loss: 3.927\n",
      "[7,    24] loss: 3.816\n",
      "[7,    30] loss: 3.755\n",
      "[7,    36] loss: 3.812\n",
      "[7,    42] loss: 3.716\n",
      "[7,    48] loss: 3.850\n",
      "[7,    54] loss: 3.869\n",
      "[7,    60] loss: 3.920\n",
      "[7,    66] loss: 3.825\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[8,     6] loss: 3.793\n",
      "[8,    12] loss: 3.833\n",
      "[8,    18] loss: 3.691\n",
      "[8,    24] loss: 3.819\n",
      "[8,    30] loss: 3.962\n",
      "[8,    36] loss: 3.842\n",
      "[8,    42] loss: 3.767\n",
      "[8,    48] loss: 3.754\n",
      "[8,    54] loss: 3.995\n",
      "[8,    60] loss: 3.827\n",
      "[8,    66] loss: 3.784\n",
      "finished training layer 1\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[1,     6] loss: 0.453\n",
      "[1,    12] loss: 1.083\n",
      "[1,    18] loss: 0.481\n",
      "[1,    24] loss: 0.890\n",
      "[1,    30] loss: 0.985\n",
      "[1,    36] loss: 0.893\n",
      "[1,    42] loss: 0.674\n",
      "[1,    48] loss: 0.598\n",
      "[1,    54] loss: 0.877\n",
      "[1,    60] loss: 0.803\n",
      "[1,    66] loss: 0.573\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[2,     6] loss: 0.495\n",
      "[2,    12] loss: 0.515\n",
      "[2,    18] loss: 0.478\n",
      "[2,    24] loss: 0.778\n",
      "[2,    30] loss: 0.469\n",
      "[2,    36] loss: 0.305\n",
      "[2,    42] loss: 0.432\n",
      "[2,    48] loss: 0.510\n",
      "[2,    54] loss: 0.374\n",
      "[2,    60] loss: 0.305\n",
      "[2,    66] loss: 0.560\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[3,     6] loss: 0.295\n",
      "[3,    12] loss: 0.300\n",
      "[3,    18] loss: 0.314\n",
      "[3,    24] loss: 0.417\n",
      "[3,    30] loss: 0.387\n",
      "[3,    36] loss: 0.397\n",
      "[3,    42] loss: 0.215\n",
      "[3,    48] loss: 0.258\n",
      "[3,    54] loss: 0.266\n",
      "[3,    60] loss: 0.408\n",
      "[3,    66] loss: 0.242\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4,     6] loss: 0.216\n",
      "[4,    12] loss: 0.177\n",
      "[4,    18] loss: 0.220\n",
      "[4,    24] loss: 0.176\n",
      "[4,    30] loss: 0.251\n",
      "[4,    36] loss: 0.268\n",
      "[4,    42] loss: 0.257\n",
      "[4,    48] loss: 0.208\n",
      "[4,    54] loss: 0.210\n",
      "[4,    60] loss: 0.195\n",
      "[4,    66] loss: 0.214\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[5,     6] loss: 0.146\n",
      "[5,    12] loss: 0.141\n",
      "[5,    18] loss: 0.222\n",
      "[5,    24] loss: 0.203\n",
      "[5,    30] loss: 0.159\n",
      "[5,    36] loss: 0.191\n",
      "[5,    42] loss: 0.129\n",
      "[5,    48] loss: 0.184\n",
      "[5,    54] loss: 0.208\n",
      "[5,    60] loss: 0.148\n",
      "[5,    66] loss: 0.146\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[6,     6] loss: 0.150\n",
      "[6,    12] loss: 0.120\n",
      "[6,    18] loss: 0.196\n",
      "[6,    24] loss: 0.158\n",
      "[6,    30] loss: 0.153\n",
      "[6,    36] loss: 0.152\n",
      "[6,    42] loss: 0.120\n",
      "[6,    48] loss: 0.128\n",
      "[6,    54] loss: 0.132\n",
      "[6,    60] loss: 0.110\n",
      "[6,    66] loss: 0.121\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[7,     6] loss: 0.075\n",
      "[7,    12] loss: 0.113\n",
      "[7,    18] loss: 0.111\n",
      "[7,    24] loss: 0.164\n",
      "[7,    30] loss: 0.120\n",
      "[7,    36] loss: 0.114\n",
      "[7,    42] loss: 0.074\n",
      "[7,    48] loss: 0.099\n",
      "[7,    54] loss: 0.157\n",
      "[7,    60] loss: 0.132\n",
      "[7,    66] loss: 0.151\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[8,     6] loss: 0.109\n",
      "[8,    12] loss: 0.110\n",
      "[8,    18] loss: 0.095\n",
      "[8,    24] loss: 0.086\n",
      "[8,    30] loss: 0.117\n",
      "[8,    36] loss: 0.122\n",
      "[8,    42] loss: 0.109\n",
      "[8,    48] loss: 0.086\n",
      "[8,    54] loss: 0.119\n",
      "[8,    60] loss: 0.099\n",
      "[8,    66] loss: 0.096\n",
      "finished training layer 2\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[1,     6] loss: 3.597\n",
      "[1,    12] loss: 3.966\n",
      "[1,    18] loss: 5.236\n",
      "[1,    24] loss: 2.852\n",
      "[1,    30] loss: 3.350\n",
      "[1,    36] loss: 1.754\n",
      "[1,    42] loss: 2.013\n",
      "[1,    48] loss: 1.149\n",
      "[1,    54] loss: 0.998\n",
      "[1,    60] loss: 1.221\n",
      "[1,    66] loss: 0.906\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[2,     6] loss: 0.726\n",
      "[2,    12] loss: 0.502\n",
      "[2,    18] loss: 0.494\n",
      "[2,    24] loss: 0.528\n",
      "[2,    30] loss: 0.451\n",
      "[2,    36] loss: 0.536\n",
      "[2,    42] loss: 0.575\n",
      "[2,    48] loss: 0.595\n",
      "[2,    54] loss: 0.559\n",
      "[2,    60] loss: 0.482\n",
      "[2,    66] loss: 0.409\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[3,     6] loss: 0.537\n",
      "[3,    12] loss: 0.398\n",
      "[3,    18] loss: 0.416\n",
      "[3,    24] loss: 0.380\n",
      "[3,    30] loss: 0.369\n",
      "[3,    36] loss: 0.449\n",
      "[3,    42] loss: 0.395\n",
      "[3,    48] loss: 0.413\n",
      "[3,    54] loss: 0.342\n",
      "[3,    60] loss: 0.363\n",
      "[3,    66] loss: 0.412\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4,     6] loss: 0.450\n",
      "[4,    12] loss: 0.322\n",
      "[4,    18] loss: 0.266\n",
      "[4,    24] loss: 0.397\n",
      "[4,    30] loss: 0.293\n",
      "[4,    36] loss: 0.453\n",
      "[4,    42] loss: 0.409\n",
      "[4,    48] loss: 0.473\n",
      "[4,    54] loss: 0.375\n",
      "[4,    60] loss: 0.419\n",
      "[4,    66] loss: 0.337\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[5,     6] loss: 0.407\n",
      "[5,    12] loss: 0.399\n",
      "[5,    18] loss: 0.334\n",
      "[5,    24] loss: 0.461\n",
      "[5,    30] loss: 0.310\n",
      "[5,    36] loss: 0.359\n",
      "[5,    42] loss: 0.399\n",
      "[5,    48] loss: 0.294\n",
      "[5,    54] loss: 0.362\n",
      "[5,    60] loss: 0.315\n",
      "[5,    66] loss: 0.411\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[6,     6] loss: 0.382\n",
      "[6,    12] loss: 0.365\n",
      "[6,    18] loss: 0.376\n",
      "[6,    24] loss: 0.370\n",
      "[6,    30] loss: 0.341\n",
      "[6,    36] loss: 0.371\n",
      "[6,    42] loss: 0.362\n",
      "[6,    48] loss: 0.393\n",
      "[6,    54] loss: 0.342\n",
      "[6,    60] loss: 0.416\n",
      "[6,    66] loss: 0.280\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[7,     6] loss: 0.369\n",
      "[7,    12] loss: 0.350\n",
      "[7,    18] loss: 0.338\n",
      "[7,    24] loss: 0.345\n",
      "[7,    30] loss: 0.445\n",
      "[7,    36] loss: 0.419\n",
      "[7,    42] loss: 0.326\n",
      "[7,    48] loss: 0.289\n",
      "[7,    54] loss: 0.344\n",
      "[7,    60] loss: 0.419\n",
      "[7,    66] loss: 0.314\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[8,     6] loss: 0.297\n",
      "[8,    12] loss: 0.385\n",
      "[8,    18] loss: 0.361\n",
      "[8,    24] loss: 0.407\n",
      "[8,    30] loss: 0.312\n",
      "[8,    36] loss: 0.391\n",
      "[8,    42] loss: 0.338\n",
      "[8,    48] loss: 0.354\n",
      "[8,    54] loss: 0.375\n",
      "[8,    60] loss: 0.341\n",
      "[8,    66] loss: 0.373\n",
      "finished training layer 3\n"
     ]
    }
   ],
   "source": [
    "#greedy training \n",
    "\n",
    "layers = [773,100,100,100]\n",
    "W, B, C = [], [], []\n",
    "\n",
    "for i in range(len(layers)-1):\n",
    "    w = torch.randn((layers[i],layers[i+1]),dtype=torch.float)\n",
    "    c = torch.randn((layers[i]),dtype=torch.float)\n",
    "    b = torch.randn((layers[i+1]),dtype=torch.float)\n",
    "    \n",
    "    parameters = [w, c, b]\n",
    "    for p in parameters:\n",
    "        p.requires_grad = True\n",
    "\n",
    "    optimizer = optim.SGD(parameters,lr=0.1)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    epochs = 8\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "        for batch, (x, _) in enumerate(dbn_dataloader):\n",
    "            if i > 0:\n",
    "                for j in range(len(W)):\n",
    "                    x = torch.relu(x @ W[j] + B[j])\n",
    "\n",
    "            probs = torch.relu((torch.relu(x @ w + b) @ w.T) + c)\n",
    "            loss = criterion(probs,x)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if batch % 6 == 5:\n",
    "                print(f'[{epoch + 1}, {batch + 1:5d}] loss: {running_loss / 200:.3f}')\n",
    "                running_loss = 0.0\n",
    "        losses.append(running_loss)\n",
    "        \n",
    "    print(f'finished training layer {i+1}')\n",
    "    W.append(w.clone().detach())\n",
    "    B.append(b.clone().detach())\n",
    "    C.append(c.clone().detach())\n",
    "    \n",
    "    for p in parameters: del p\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 773]), torch.Size([64, 773]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = X[:64,:]\n",
    "w = torch.randn((773,100),dtype=torch.float)\n",
    "c = torch.randn((773),dtype=torch.float)\n",
    "b = torch.randn((100),dtype=torch.float)\n",
    "torch.sigmoid((torch.sigmoid(x @ w + b) @ w.T) + c).shape, x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
