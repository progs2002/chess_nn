{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from extractor import get_dataset\n",
    "\n",
    "path = 'dataset/games.pgn'\n",
    "num_games = 2000\n",
    "device ='cuda'\n",
    "\n",
    "X, Y = get_dataset(path, num_games=num_games, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([156961, 773]), torch.Size([156961]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_matrix(x):\n",
    "    img = torch.zeros((784))\n",
    "    img[:x.shape[0]] = x.to(device).detach().clone()\n",
    "    plt.imshow(img.view(28,28),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_matrix(X[69])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(773,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,100)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(100,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,773),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.decoder(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X,Y)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 773])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track = X[0].view(1,-1).detach()\n",
    "track.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.248\n",
      "[1,   400] loss: 0.246\n",
      "[1,   600] loss: 0.244\n",
      "[1,   800] loss: 0.241\n",
      "[1,  1000] loss: 0.238\n",
      "[1,  1200] loss: 0.234\n",
      "[1,  1400] loss: 0.228\n",
      "[1,  1600] loss: 0.217\n",
      "[1,  1800] loss: 0.191\n",
      "[1,  2000] loss: 0.107\n",
      "[1,  2200] loss: 0.033\n",
      "[1,  2400] loss: 0.026\n",
      "[2,   200] loss: 0.025\n",
      "[2,   400] loss: 0.025\n",
      "[2,   600] loss: 0.024\n",
      "[2,   800] loss: 0.024\n",
      "[2,  1000] loss: 0.024\n",
      "[2,  1200] loss: 0.024\n",
      "[2,  1400] loss: 0.024\n",
      "[2,  1600] loss: 0.024\n",
      "[2,  1800] loss: 0.024\n",
      "[2,  2000] loss: 0.024\n",
      "[2,  2200] loss: 0.024\n",
      "[2,  2400] loss: 0.024\n",
      "[3,   200] loss: 0.024\n",
      "[3,   400] loss: 0.024\n",
      "[3,   600] loss: 0.023\n",
      "[3,   800] loss: 0.023\n",
      "[3,  1000] loss: 0.023\n",
      "[3,  1200] loss: 0.023\n",
      "[3,  1400] loss: 0.023\n",
      "[3,  1600] loss: 0.023\n",
      "[3,  1800] loss: 0.023\n",
      "[3,  2000] loss: 0.023\n",
      "[3,  2200] loss: 0.023\n",
      "[3,  2400] loss: 0.023\n",
      "[4,   200] loss: 0.023\n",
      "[4,   400] loss: 0.023\n",
      "[4,   600] loss: 0.023\n",
      "[4,   800] loss: 0.023\n",
      "[4,  1000] loss: 0.023\n",
      "[4,  1200] loss: 0.023\n",
      "[4,  1400] loss: 0.023\n",
      "[4,  1600] loss: 0.023\n",
      "[4,  1800] loss: 0.023\n",
      "[4,  2000] loss: 0.023\n",
      "[4,  2200] loss: 0.023\n",
      "[4,  2400] loss: 0.023\n",
      "[5,   200] loss: 0.023\n",
      "[5,   400] loss: 0.023\n",
      "[5,   600] loss: 0.023\n",
      "[5,   800] loss: 0.023\n",
      "[5,  1000] loss: 0.023\n",
      "[5,  1200] loss: 0.023\n",
      "[5,  1400] loss: 0.022\n",
      "[5,  1600] loss: 0.022\n",
      "[5,  1800] loss: 0.023\n",
      "[5,  2000] loss: 0.022\n",
      "[5,  2200] loss: 0.022\n",
      "[5,  2400] loss: 0.022\n",
      "[6,   200] loss: 0.022\n",
      "[6,   400] loss: 0.022\n",
      "[6,   600] loss: 0.022\n",
      "[6,   800] loss: 0.022\n",
      "[6,  1000] loss: 0.022\n",
      "[6,  1200] loss: 0.022\n",
      "[6,  1400] loss: 0.022\n",
      "[6,  1600] loss: 0.022\n",
      "[6,  1800] loss: 0.022\n",
      "[6,  2000] loss: 0.022\n",
      "[6,  2200] loss: 0.022\n",
      "[6,  2400] loss: 0.022\n",
      "[7,   200] loss: 0.022\n",
      "[7,   400] loss: 0.022\n",
      "[7,   600] loss: 0.022\n",
      "[7,   800] loss: 0.022\n",
      "[7,  1000] loss: 0.022\n",
      "[7,  1200] loss: 0.022\n",
      "[7,  1400] loss: 0.022\n",
      "[7,  1600] loss: 0.022\n",
      "[7,  1800] loss: 0.022\n",
      "[7,  2000] loss: 0.022\n",
      "[7,  2200] loss: 0.022\n",
      "[7,  2400] loss: 0.022\n",
      "[8,   200] loss: 0.022\n",
      "[8,   400] loss: 0.022\n",
      "[8,   600] loss: 0.022\n",
      "[8,   800] loss: 0.022\n",
      "[8,  1000] loss: 0.022\n",
      "[8,  1200] loss: 0.022\n",
      "[8,  1400] loss: 0.022\n",
      "[8,  1600] loss: 0.022\n",
      "[8,  1800] loss: 0.022\n",
      "[8,  2000] loss: 0.022\n",
      "[8,  2200] loss: 0.022\n",
      "[8,  2400] loss: 0.022\n",
      "[9,   200] loss: 0.022\n",
      "[9,   400] loss: 0.022\n",
      "[9,   600] loss: 0.022\n",
      "[9,   800] loss: 0.022\n",
      "[9,  1000] loss: 0.022\n",
      "[9,  1200] loss: 0.022\n",
      "[9,  1400] loss: 0.022\n",
      "[9,  1600] loss: 0.022\n",
      "[9,  1800] loss: 0.022\n",
      "[9,  2000] loss: 0.022\n",
      "[9,  2200] loss: 0.022\n",
      "[9,  2400] loss: 0.022\n",
      "[10,   200] loss: 0.022\n",
      "[10,   400] loss: 0.022\n",
      "[10,   600] loss: 0.022\n",
      "[10,   800] loss: 0.022\n",
      "[10,  1000] loss: 0.022\n",
      "[10,  1200] loss: 0.022\n",
      "[10,  1400] loss: 0.022\n",
      "[10,  1600] loss: 0.022\n",
      "[10,  1800] loss: 0.022\n",
      "[10,  2000] loss: 0.022\n",
      "[10,  2200] loss: 0.022\n",
      "[10,  2400] loss: 0.022\n",
      "finished_training\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "outputs = []\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for batch, (x, _) in enumerate(loader):\n",
    "        out = model(x)\n",
    "        loss = criterion(out,x)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch % (num_games//10) == (num_games//10) - 1:\n",
    "            print(f'[{epoch + 1}, {batch + 1:5d}] loss: {running_loss / (num_games//10):.3f}')\n",
    "            running_loss = 0.0\n",
    "    losses.append(running_loss)\n",
    "    outputs.append(model(track))\n",
    "print('finished_training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 773]), torch.Size([1, 773]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape, track.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_matrix(track[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_matrix(outputs[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = model.encoder\n",
    "e2 = model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = X[0], X[1]\n",
    "a, b = e1(a), e2(b)\n",
    "r = torch.cat((a,b),dim=0)\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepChess(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.e = model.encoder\n",
    "        self.fc1 = nn.Linear(200,100)\n",
    "        self.fc2 = nn.Linear(100,100)\n",
    "        self.fc3 = nn.Linear(100,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = DeepChess().to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader1 = DataLoader(dataset,batch_size=64,shuffle=True)\n",
    "loader2 = DataLoader(dataset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 200])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand((64,773),device=device)\n",
    "b = torch.rand((64,773),device=device)\n",
    "a = model.encoder(a)\n",
    "b = model.encoder(b)\n",
    "c = torch.cat((a,b),-1)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0134,  0.0292, -0.0316,  ...,  0.0016,  0.0216, -0.0324],\n",
       "        [-0.0216,  0.0085,  0.0128,  ...,  0.0234, -0.0255,  0.0167],\n",
       "        [-0.0248, -0.0063, -0.0276,  ..., -0.0254, -0.0251, -0.0234],\n",
       "        ...,\n",
       "        [-0.0181,  0.0002,  0.0182,  ...,  0.0224, -0.0209, -0.0074],\n",
       "        [-0.0082, -0.0017,  0.0135,  ..., -0.0296, -0.0184,  0.0207],\n",
       "        [-0.0341,  0.0236, -0.0180,  ...,  0.0160, -0.0205, -0.0197]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = net.e[0].weight.detach().clone()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10101/1446901922.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(torch.stack((y1,y2),dim=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.739\n",
      "[1,   400] loss: 0.749\n",
      "[1,   600] loss: 0.748\n",
      "[1,   800] loss: 0.744\n",
      "[1,  1000] loss: 0.743\n",
      "[1,  1200] loss: 0.741\n",
      "[1,  1400] loss: 0.748\n",
      "[1,  1600] loss: 0.747\n",
      "[1,  1800] loss: 0.742\n",
      "[1,  2000] loss: 0.746\n",
      "[1,  2200] loss: 0.741\n",
      "[1,  2400] loss: 0.741\n",
      "[2,   200] loss: 0.743\n",
      "[2,   400] loss: 0.739\n",
      "[2,   600] loss: 0.733\n",
      "[2,   800] loss: 0.729\n",
      "[2,  1000] loss: 0.716\n",
      "[2,  1200] loss: 0.712\n",
      "[2,  1400] loss: 0.689\n",
      "[2,  1600] loss: 0.668\n",
      "[2,  1800] loss: 0.660\n",
      "[2,  2000] loss: 0.652\n",
      "[2,  2200] loss: 0.635\n",
      "[2,  2400] loss: 0.619\n",
      "[3,   200] loss: 0.600\n",
      "[3,   400] loss: 0.587\n",
      "[3,   600] loss: 0.564\n",
      "[3,   800] loss: 0.556\n",
      "[3,  1000] loss: 0.562\n",
      "[3,  1200] loss: 0.535\n",
      "[3,  1400] loss: 0.537\n",
      "[3,  1600] loss: 0.527\n",
      "[3,  1800] loss: 0.525\n",
      "[3,  2000] loss: 0.521\n",
      "[3,  2200] loss: 0.517\n",
      "[3,  2400] loss: 0.514\n",
      "[4,   200] loss: 0.516\n",
      "[4,   400] loss: 0.500\n",
      "[4,   600] loss: 0.506\n",
      "[4,   800] loss: 0.495\n",
      "[4,  1000] loss: 0.494\n",
      "[4,  1200] loss: 0.486\n",
      "[4,  1400] loss: 0.496\n",
      "[4,  1600] loss: 0.494\n",
      "[4,  1800] loss: 0.495\n",
      "[4,  2000] loss: 0.498\n",
      "[4,  2200] loss: 0.488\n",
      "[4,  2400] loss: 0.483\n",
      "[5,   200] loss: 0.488\n",
      "[5,   400] loss: 0.480\n",
      "[5,   600] loss: 0.476\n",
      "[5,   800] loss: 0.479\n",
      "[5,  1000] loss: 0.474\n",
      "[5,  1200] loss: 0.489\n",
      "[5,  1400] loss: 0.480\n",
      "[5,  1600] loss: 0.471\n",
      "[5,  1800] loss: 0.467\n",
      "[5,  2000] loss: 0.473\n",
      "[5,  2200] loss: 0.465\n",
      "[5,  2400] loss: 0.477\n",
      "[6,   200] loss: 0.469\n",
      "[6,   400] loss: 0.479\n",
      "[6,   600] loss: 0.469\n",
      "[6,   800] loss: 0.467\n",
      "[6,  1000] loss: 0.469\n",
      "[6,  1200] loss: 0.472\n",
      "[6,  1400] loss: 0.469\n",
      "[6,  1600] loss: 0.474\n",
      "[6,  1800] loss: 0.465\n",
      "[6,  2000] loss: 0.469\n",
      "[6,  2200] loss: 0.463\n",
      "[6,  2400] loss: 0.474\n",
      "[7,   200] loss: 0.479\n",
      "[7,   400] loss: 0.464\n",
      "[7,   600] loss: 0.466\n",
      "[7,   800] loss: 0.470\n",
      "[7,  1000] loss: 0.459\n",
      "[7,  1200] loss: 0.463\n",
      "[7,  1400] loss: 0.455\n",
      "[7,  1600] loss: 0.459\n",
      "[7,  1800] loss: 0.466\n",
      "[7,  2000] loss: 0.459\n",
      "[7,  2200] loss: 0.466\n",
      "[7,  2400] loss: 0.453\n",
      "[8,   200] loss: 0.456\n",
      "[8,   400] loss: 0.442\n",
      "[8,   600] loss: 0.465\n",
      "[8,   800] loss: 0.447\n",
      "[8,  1000] loss: 0.460\n",
      "[8,  1200] loss: 0.454\n",
      "[8,  1400] loss: 0.459\n",
      "[8,  1600] loss: 0.457\n",
      "[8,  1800] loss: 0.462\n",
      "[8,  2000] loss: 0.470\n",
      "[8,  2200] loss: 0.453\n",
      "[8,  2400] loss: 0.456\n",
      "[9,   200] loss: 0.451\n",
      "[9,   400] loss: 0.444\n",
      "[9,   600] loss: 0.455\n",
      "[9,   800] loss: 0.462\n",
      "[9,  1000] loss: 0.448\n",
      "[9,  1200] loss: 0.462\n",
      "[9,  1400] loss: 0.447\n",
      "[9,  1600] loss: 0.450\n",
      "[9,  1800] loss: 0.458\n",
      "[9,  2000] loss: 0.460\n",
      "[9,  2200] loss: 0.452\n",
      "[9,  2400] loss: 0.451\n",
      "[10,   200] loss: 0.447\n",
      "[10,   400] loss: 0.456\n",
      "[10,   600] loss: 0.440\n",
      "[10,   800] loss: 0.450\n",
      "[10,  1000] loss: 0.450\n",
      "[10,  1200] loss: 0.453\n",
      "[10,  1400] loss: 0.454\n",
      "[10,  1600] loss: 0.452\n",
      "[10,  1800] loss: 0.464\n",
      "[10,  2000] loss: 0.462\n",
      "[10,  2200] loss: 0.456\n",
      "[10,  2400] loss: 0.449\n",
      "[11,   200] loss: 0.460\n",
      "[11,   400] loss: 0.443\n",
      "[11,   600] loss: 0.462\n",
      "[11,   800] loss: 0.454\n",
      "[11,  1000] loss: 0.448\n",
      "[11,  1200] loss: 0.464\n",
      "[11,  1400] loss: 0.447\n",
      "[11,  1600] loss: 0.458\n",
      "[11,  1800] loss: 0.450\n",
      "[11,  2000] loss: 0.448\n",
      "[11,  2200] loss: 0.449\n",
      "[11,  2400] loss: 0.445\n",
      "[12,   200] loss: 0.449\n",
      "[12,   400] loss: 0.446\n",
      "[12,   600] loss: 0.447\n",
      "[12,   800] loss: 0.461\n",
      "[12,  1000] loss: 0.453\n",
      "[12,  1200] loss: 0.450\n",
      "[12,  1400] loss: 0.453\n",
      "[12,  1600] loss: 0.454\n",
      "[12,  1800] loss: 0.445\n",
      "[12,  2000] loss: 0.448\n",
      "[12,  2200] loss: 0.454\n",
      "[12,  2400] loss: 0.455\n",
      "[13,   200] loss: 0.438\n",
      "[13,   400] loss: 0.450\n",
      "[13,   600] loss: 0.458\n",
      "[13,   800] loss: 0.448\n",
      "[13,  1000] loss: 0.457\n",
      "[13,  1200] loss: 0.449\n",
      "[13,  1400] loss: 0.447\n",
      "[13,  1600] loss: 0.446\n",
      "[13,  1800] loss: 0.450\n",
      "[13,  2000] loss: 0.452\n",
      "[13,  2200] loss: 0.441\n",
      "[13,  2400] loss: 0.441\n",
      "[14,   200] loss: 0.447\n",
      "[14,   400] loss: 0.444\n",
      "[14,   600] loss: 0.448\n",
      "[14,   800] loss: 0.445\n",
      "[14,  1000] loss: 0.445\n",
      "[14,  1200] loss: 0.444\n",
      "[14,  1400] loss: 0.442\n",
      "[14,  1600] loss: 0.452\n",
      "[14,  1800] loss: 0.451\n",
      "[14,  2000] loss: 0.458\n",
      "[14,  2200] loss: 0.444\n",
      "[14,  2400] loss: 0.447\n",
      "[15,   200] loss: 0.437\n",
      "[15,   400] loss: 0.436\n",
      "[15,   600] loss: 0.456\n",
      "[15,   800] loss: 0.443\n",
      "[15,  1000] loss: 0.437\n",
      "[15,  1200] loss: 0.454\n",
      "[15,  1400] loss: 0.444\n",
      "[15,  1600] loss: 0.440\n",
      "[15,  1800] loss: 0.457\n",
      "[15,  2000] loss: 0.454\n",
      "[15,  2200] loss: 0.445\n",
      "[15,  2400] loss: 0.432\n",
      "[16,   200] loss: 0.445\n",
      "[16,   400] loss: 0.447\n",
      "[16,   600] loss: 0.446\n",
      "[16,   800] loss: 0.455\n",
      "[16,  1000] loss: 0.446\n",
      "[16,  1200] loss: 0.445\n",
      "[16,  1400] loss: 0.445\n",
      "[16,  1600] loss: 0.446\n",
      "[16,  1800] loss: 0.448\n",
      "[16,  2000] loss: 0.447\n",
      "[16,  2200] loss: 0.448\n",
      "[16,  2400] loss: 0.445\n",
      "[17,   200] loss: 0.436\n",
      "[17,   400] loss: 0.450\n",
      "[17,   600] loss: 0.452\n",
      "[17,   800] loss: 0.441\n",
      "[17,  1000] loss: 0.447\n",
      "[17,  1200] loss: 0.445\n",
      "[17,  1400] loss: 0.450\n",
      "[17,  1600] loss: 0.449\n",
      "[17,  1800] loss: 0.446\n",
      "[17,  2000] loss: 0.443\n",
      "[17,  2200] loss: 0.452\n",
      "[17,  2400] loss: 0.443\n",
      "[18,   200] loss: 0.448\n",
      "[18,   400] loss: 0.453\n",
      "[18,   600] loss: 0.436\n",
      "[18,   800] loss: 0.443\n",
      "[18,  1000] loss: 0.441\n",
      "[18,  1200] loss: 0.443\n",
      "[18,  1400] loss: 0.452\n",
      "[18,  1600] loss: 0.443\n",
      "[18,  1800] loss: 0.435\n",
      "[18,  2000] loss: 0.452\n",
      "[18,  2200] loss: 0.450\n",
      "[18,  2400] loss: 0.444\n",
      "[19,   200] loss: 0.443\n",
      "[19,   400] loss: 0.445\n",
      "[19,   600] loss: 0.433\n",
      "[19,   800] loss: 0.452\n",
      "[19,  1000] loss: 0.444\n",
      "[19,  1200] loss: 0.442\n",
      "[19,  1400] loss: 0.446\n",
      "[19,  1600] loss: 0.442\n",
      "[19,  1800] loss: 0.445\n",
      "[19,  2000] loss: 0.443\n",
      "[19,  2200] loss: 0.446\n",
      "[19,  2400] loss: 0.453\n",
      "[20,   200] loss: 0.447\n",
      "[20,   400] loss: 0.443\n",
      "[20,   600] loss: 0.444\n",
      "[20,   800] loss: 0.441\n",
      "[20,  1000] loss: 0.435\n",
      "[20,  1200] loss: 0.448\n",
      "[20,  1400] loss: 0.438\n",
      "[20,  1600] loss: 0.434\n",
      "[20,  1800] loss: 0.441\n",
      "[20,  2000] loss: 0.447\n",
      "[20,  2200] loss: 0.441\n",
      "[20,  2400] loss: 0.449\n",
      "finished_training\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for batch, (data1, data2) in enumerate(zip(loader1,loader2)):\n",
    "        x1, y1 = data1\n",
    "        x2, y2 = data2\n",
    "        x1 = net.e(x1)\n",
    "        x2 = net.e(x2)\n",
    "        x = torch.cat((x1,x2),-1) \n",
    "        pred = net(x)\n",
    "        \n",
    "        target = torch.tensor(torch.stack((y1,y2),dim=1))\n",
    "        loss = criterion(pred, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if batch % (num_games//10) == (num_games//10) - 1:\n",
    "            print(f'[{epoch + 1}, {batch + 1:5d}] loss: {running_loss / (num_games//10):.3f}')\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    losses.append(running_loss)\n",
    "\n",
    "print('finished_training')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
