{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(773,100)\n",
    "        self.fc2 = nn.Linear(100,100)\n",
    "        self.fc3 = nn.Linear(100,100)\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbn = DBN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from extractor import get_dataset\n",
    "path = 'dataset/games.pgn'\n",
    "num_games = 50\n",
    "\n",
    "X, Y = get_dataset(path, num_games)\n",
    "X = X.type(torch.FloatTensor)\n",
    "Y = Y.type(torch.FloatTensor)\n",
    "len_data = X.shape[0]\n",
    "split = int(len_data*0.8)\n",
    "X_train = X[:split,:]\n",
    "X_test = X[split:,:]\n",
    "Y_train = Y[:split]\n",
    "Y_test = Y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbn_dataset = TensorDataset(X, torch.zeros((X.shape[0])))\n",
    "dbn_dataloader = DataLoader(dbn_dataset, batch_size=64, shuffle=True)\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "train_datalaoder = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test, Y_test)\n",
    "test_datalaoder = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "[1,     6] loss: 29.954\n",
      "[1,    12] loss: 8.278\n",
      "[1,    18] loss: 6.172\n",
      "[1,    24] loss: 5.457\n",
      "[1,    30] loss: 5.015\n",
      "[1,    36] loss: 4.870\n",
      "[1,    42] loss: 4.568\n",
      "[1,    48] loss: 4.516\n",
      "[1,    54] loss: 4.437\n",
      "[1,    60] loss: 4.342\n",
      "[1,    66] loss: 4.118\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[2,     6] loss: 4.169\n",
      "[2,    12] loss: 4.130\n",
      "[2,    18] loss: 4.059\n",
      "[2,    24] loss: 4.137\n",
      "[2,    30] loss: 4.051\n",
      "[2,    36] loss: 4.049\n",
      "[2,    42] loss: 4.117\n",
      "[2,    48] loss: 3.870\n",
      "[2,    54] loss: 4.021\n",
      "[2,    60] loss: 3.818\n",
      "[2,    66] loss: 3.980\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[3,     6] loss: 4.055\n",
      "[3,    12] loss: 3.802\n",
      "[3,    18] loss: 3.978\n",
      "[3,    24] loss: 4.002\n",
      "[3,    30] loss: 3.866\n",
      "[3,    36] loss: 3.829\n",
      "[3,    42] loss: 3.869\n",
      "[3,    48] loss: 3.840\n",
      "[3,    54] loss: 3.765\n",
      "[3,    60] loss: 3.811\n",
      "[3,    66] loss: 3.775\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4,     6] loss: 3.853\n",
      "[4,    12] loss: 3.958\n",
      "[4,    18] loss: 3.690\n",
      "[4,    24] loss: 3.739\n",
      "[4,    30] loss: 3.867\n",
      "[4,    36] loss: 3.838\n",
      "[4,    42] loss: 3.797\n",
      "[4,    48] loss: 3.895\n",
      "[4,    54] loss: 3.759\n",
      "[4,    60] loss: 3.741\n",
      "[4,    66] loss: 3.725\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[5,     6] loss: 3.873\n",
      "[5,    12] loss: 3.814\n",
      "[5,    18] loss: 3.813\n",
      "[5,    24] loss: 3.741\n",
      "[5,    30] loss: 3.770\n",
      "[5,    36] loss: 3.845\n",
      "[5,    42] loss: 3.719\n",
      "[5,    48] loss: 3.732\n",
      "[5,    54] loss: 3.748\n",
      "[5,    60] loss: 3.799\n",
      "[5,    66] loss: 3.712\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[6,     6] loss: 3.757\n",
      "[6,    12] loss: 3.774\n",
      "[6,    18] loss: 3.808\n",
      "[6,    24] loss: 3.836\n",
      "[6,    30] loss: 3.701\n",
      "[6,    36] loss: 3.676\n",
      "[6,    42] loss: 3.782\n",
      "[6,    48] loss: 3.722\n",
      "[6,    54] loss: 3.740\n",
      "[6,    60] loss: 3.873\n",
      "[6,    66] loss: 3.738\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[7,     6] loss: 3.843\n",
      "[7,    12] loss: 3.864\n",
      "[7,    18] loss: 3.728\n",
      "[7,    24] loss: 3.820\n",
      "[7,    30] loss: 3.738\n",
      "[7,    36] loss: 3.609\n",
      "[7,    42] loss: 3.747\n",
      "[7,    48] loss: 3.710\n",
      "[7,    54] loss: 3.646\n",
      "[7,    60] loss: 3.694\n",
      "[7,    66] loss: 3.842\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[8,     6] loss: 3.708\n",
      "[8,    12] loss: 3.868\n",
      "[8,    18] loss: 3.886\n",
      "[8,    24] loss: 3.747\n",
      "[8,    30] loss: 3.829\n",
      "[8,    36] loss: 3.641\n",
      "[8,    42] loss: 3.632\n",
      "[8,    48] loss: 3.751\n",
      "[8,    54] loss: 3.723\n",
      "[8,    60] loss: 3.687\n",
      "[8,    66] loss: 3.680\n",
      "finished training layer 1\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[1,     6] loss: 1.057\n",
      "[1,    12] loss: 0.586\n",
      "[1,    18] loss: 0.314\n",
      "[1,    24] loss: 0.274\n",
      "[1,    30] loss: 0.234\n",
      "[1,    36] loss: 0.172\n",
      "[1,    42] loss: 0.159\n",
      "[1,    48] loss: 0.221\n",
      "[1,    54] loss: 0.073\n",
      "[1,    60] loss: 0.211\n",
      "[1,    66] loss: 0.103\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[2,     6] loss: 0.038\n",
      "[2,    12] loss: 0.102\n",
      "[2,    18] loss: 0.078\n",
      "[2,    24] loss: 0.082\n",
      "[2,    30] loss: 0.043\n",
      "[2,    36] loss: 0.042\n",
      "[2,    42] loss: 0.095\n",
      "[2,    48] loss: 0.016\n",
      "[2,    54] loss: 0.015\n",
      "[2,    60] loss: 0.005\n",
      "[2,    66] loss: 0.023\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[3,     6] loss: 0.022\n",
      "[3,    12] loss: 0.009\n",
      "[3,    18] loss: 0.021\n",
      "[3,    24] loss: 0.022\n",
      "[3,    30] loss: 0.033\n",
      "[3,    36] loss: 0.020\n",
      "[3,    42] loss: 0.028\n",
      "[3,    48] loss: 0.038\n",
      "[3,    54] loss: 0.031\n",
      "[3,    60] loss: 0.019\n",
      "[3,    66] loss: 0.009\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4,     6] loss: 0.007\n",
      "[4,    12] loss: 0.004\n",
      "[4,    18] loss: 0.010\n",
      "[4,    24] loss: 0.012\n",
      "[4,    30] loss: 0.009\n",
      "[4,    36] loss: 0.023\n",
      "[4,    42] loss: 0.019\n",
      "[4,    48] loss: 0.013\n",
      "[4,    54] loss: 0.017\n",
      "[4,    60] loss: 0.021\n",
      "[4,    66] loss: 0.009\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[5,     6] loss: 0.008\n",
      "[5,    12] loss: 0.010\n",
      "[5,    18] loss: 0.014\n",
      "[5,    24] loss: 0.006\n",
      "[5,    30] loss: 0.015\n",
      "[5,    36] loss: 0.006\n",
      "[5,    42] loss: 0.005\n",
      "[5,    48] loss: 0.007\n",
      "[5,    54] loss: 0.005\n",
      "[5,    60] loss: 0.015\n",
      "[5,    66] loss: 0.019\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[6,     6] loss: 0.014\n",
      "[6,    12] loss: 0.003\n",
      "[6,    18] loss: 0.011\n",
      "[6,    24] loss: 0.006\n",
      "[6,    30] loss: 0.006\n",
      "[6,    36] loss: 0.003\n",
      "[6,    42] loss: 0.008\n",
      "[6,    48] loss: 0.002\n",
      "[6,    54] loss: 0.015\n",
      "[6,    60] loss: 0.016\n",
      "[6,    66] loss: 0.003\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[7,     6] loss: 0.006\n",
      "[7,    12] loss: 0.004\n",
      "[7,    18] loss: 0.002\n",
      "[7,    24] loss: 0.008\n",
      "[7,    30] loss: 0.006\n",
      "[7,    36] loss: 0.014\n",
      "[7,    42] loss: 0.012\n",
      "[7,    48] loss: 0.001\n",
      "[7,    54] loss: 0.002\n",
      "[7,    60] loss: 0.007\n",
      "[7,    66] loss: 0.003\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[8,     6] loss: 0.005\n",
      "[8,    12] loss: 0.008\n",
      "[8,    18] loss: 0.005\n",
      "[8,    24] loss: 0.002\n",
      "[8,    30] loss: 0.007\n",
      "[8,    36] loss: 0.011\n",
      "[8,    42] loss: 0.003\n",
      "[8,    48] loss: 0.003\n",
      "[8,    54] loss: 0.005\n",
      "[8,    60] loss: 0.003\n",
      "[8,    66] loss: 0.003\n",
      "finished training layer 2\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[1,     6] loss: 2580.745\n",
      "[1,    12] loss: 4.889\n",
      "[1,    18] loss: 0.000\n",
      "[1,    24] loss: 0.275\n",
      "[1,    30] loss: 0.000\n",
      "[1,    36] loss: 0.524\n",
      "[1,    42] loss: 0.000\n",
      "[1,    48] loss: 0.000\n",
      "[1,    54] loss: 0.000\n",
      "[1,    60] loss: 0.242\n",
      "[1,    66] loss: 0.000\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[2,     6] loss: 0.000\n",
      "[2,    12] loss: 0.000\n",
      "[2,    18] loss: 0.000\n",
      "[2,    24] loss: 0.000\n",
      "[2,    30] loss: 0.000\n",
      "[2,    36] loss: 0.000\n",
      "[2,    42] loss: 0.000\n",
      "[2,    48] loss: 0.000\n",
      "[2,    54] loss: 0.000\n",
      "[2,    60] loss: 0.000\n",
      "[2,    66] loss: 0.000\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[3,     6] loss: 0.000\n",
      "[3,    12] loss: 0.000\n",
      "[3,    18] loss: 0.000\n",
      "[3,    24] loss: 0.000\n",
      "[3,    30] loss: 0.000\n",
      "[3,    36] loss: 0.000\n",
      "[3,    42] loss: 0.000\n",
      "[3,    48] loss: 0.000\n",
      "[3,    54] loss: 0.000\n",
      "[3,    60] loss: 0.000\n",
      "[3,    66] loss: 0.000\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4,     6] loss: 0.000\n",
      "[4,    12] loss: 0.000\n",
      "[4,    18] loss: 0.000\n",
      "[4,    24] loss: 0.000\n",
      "[4,    30] loss: 0.000\n",
      "[4,    36] loss: 0.000\n",
      "[4,    42] loss: 0.000\n",
      "[4,    48] loss: 0.000\n",
      "[4,    54] loss: 0.000\n",
      "[4,    60] loss: 0.000\n",
      "[4,    66] loss: 0.000\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[5,     6] loss: 0.000\n",
      "[5,    12] loss: 0.000\n",
      "[5,    18] loss: 0.000\n",
      "[5,    24] loss: 0.000\n",
      "[5,    30] loss: 0.000\n",
      "[5,    36] loss: 0.000\n",
      "[5,    42] loss: 0.000\n",
      "[5,    48] loss: 0.000\n",
      "[5,    54] loss: 0.000\n",
      "[5,    60] loss: 0.000\n",
      "[5,    66] loss: 0.000\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[6,     6] loss: 0.000\n",
      "[6,    12] loss: 0.000\n",
      "[6,    18] loss: 0.000\n",
      "[6,    24] loss: 0.000\n",
      "[6,    30] loss: 0.000\n",
      "[6,    36] loss: 0.000\n",
      "[6,    42] loss: 0.000\n",
      "[6,    48] loss: 0.000\n",
      "[6,    54] loss: 0.000\n",
      "[6,    60] loss: 0.000\n",
      "[6,    66] loss: 0.000\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[7,     6] loss: 0.000\n",
      "[7,    12] loss: 0.000\n",
      "[7,    18] loss: 0.000\n",
      "[7,    24] loss: 0.000\n",
      "[7,    30] loss: 0.000\n",
      "[7,    36] loss: 0.000\n",
      "[7,    42] loss: 0.000\n",
      "[7,    48] loss: 0.000\n",
      "[7,    54] loss: 0.000\n",
      "[7,    60] loss: 0.000\n",
      "[7,    66] loss: 0.000\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[8,     6] loss: 0.000\n",
      "[8,    12] loss: 0.000\n",
      "[8,    18] loss: 0.000\n",
      "[8,    24] loss: 0.000\n",
      "[8,    30] loss: 0.000\n",
      "[8,    36] loss: 0.000\n",
      "[8,    42] loss: 0.000\n",
      "[8,    48] loss: 0.000\n",
      "[8,    54] loss: 0.000\n",
      "[8,    60] loss: 0.000\n",
      "[8,    66] loss: 0.000\n",
      "finished training layer 3\n"
     ]
    }
   ],
   "source": [
    "#greedy training \n",
    "\n",
    "layers = [773,100,100,100]\n",
    "W, B, C = [], [], []\n",
    "\n",
    "for i in range(len(layers)-1):\n",
    "    w = torch.randn((layers[i],layers[i+1]),dtype=torch.float)\n",
    "    c = torch.randn((layers[i]),dtype=torch.float) if i==0 else B[i-1]\n",
    "    b = torch.randn((layers[i+1]),dtype=torch.float)\n",
    "    \n",
    "    parameters = [w, c, b]\n",
    "    for p in parameters:\n",
    "        p.requires_grad = True\n",
    "\n",
    "    optimizer = optim.SGD(parameters,lr=0.1)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    epochs = 8\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "        for batch, (x, _) in enumerate(dbn_dataloader):\n",
    "            if i > 0:\n",
    "                for j in range(len(W)):\n",
    "                    x = torch.relu(x @ W[j] + B[j])\n",
    "\n",
    "            probs = torch.relu((torch.relu(x @ w + b) @ w.T) + c)\n",
    "            loss = criterion(probs,x)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if batch % 6 == 5:\n",
    "                print(f'[{epoch + 1}, {batch + 1:5d}] loss: {running_loss / 200:.3f}')\n",
    "                running_loss = 0.0\n",
    "        losses.append(running_loss)\n",
    "        \n",
    "    print(f'finished training layer {i+1}')\n",
    "    W.append(w.clone().detach())\n",
    "    B.append(b.clone().detach())\n",
    "    C.append(c.clone().detach())\n",
    "    \n",
    "    for p in parameters: del p\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
